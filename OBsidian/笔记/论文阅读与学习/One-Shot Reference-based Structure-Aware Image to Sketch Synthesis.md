

这篇文章主要介绍的就是如何从一张参考图像中提取**视觉特征**（图中给出的比如有艺术风格迁移，外观迁移，风格化 t 2 l 生成，纹理扩展，可控的纹理合成）
这些可以在 figure1 中看到


前文中主要介绍的有就是在之前主流的方法主要使用的是 kv injection 的方法，但是这种方法存在以下几种局限性：
1. 域差异：当内容图像（提供 Q）和风格图像（提供 KV）差异巨大的时候，两者的相似性计算就会变得非常不可靠，这样子就会导致一些错误的特征出现，
2. 误差累计：扩散模型本身是一个迭代的马尔科夫链，在这个过程中，单一的错误会在后续的去噪步骤中不断的累积和放大，最终图像的质量就会降低
3. 架构的限制，kv-injection 发生在 u-net 的残差分支中，这意味着注入的风格信息会受到原本恒等链接的限制，这样可能会导致风格化不充分

本文提出来的创新点，主要是：
1. 注意力蒸馏损失，提出了一个新颖的损失函数，他不再将 kv 特征作为属性，而是通过反向传播来优化合成图像来“蒸馏”参考图像的特征
2. ad 引导采样：将 adloss 作为一个改进的分类器引导，将其集成到扩散模型的去噪采样中，这个样子可以实现更快并且可控的图像生成


关于文章具体的方法步骤：
1. 原本的方法是 kv-injection 通过提取我们需要特征图的 kv 然后提取原本结构图的 q 然后将其进行对其计算注意力，但是这个会发现一个前文中提到的问题，就是这个所谓的风格信息（$K_s, V_s$）知识被注入到了 Unet 的残差分支中，但是由于信息的主干流存在，这个风格的影响力有限，尤其是在风格相差比较大的地方，会引起风格化不充分（当然了这个就是前文的架构的限制之中所提到过的）


关于关键方法的讲解：

3.2 **Adloss**

fig 2：
（a）![image.png](https://gitee.com/Slexy/picture/raw/master/20251109232309445.png)
讲了关键的有关于计算 adloss 的步骤，他主要的是改造了 kvinjection 的模式，基于两个并行的自注意力的计算，下面是计算当前的风格化，去查询自己的 k 和 v（代表着目标图像当前的样子）上面这个是老方法 kvinjection 的的事情，那目标图像的 q 去查询风格化图像的 k 和 v，代表我们希望目标图像想要达到的完美风格化的结果，然后这个给到的公式
$$
LAD=∥Self-Attn(Q,K,V)−Self-Attn(Q,Ks,Vs)∥
$$
即为通过计算他们两个逐像素相减的绝对值来计算出他们的 l 1 距离，这就是这篇论文所定义的 adloss

这个相比于传统的 kv-injection 的对比就在下面的这张图：
![image.png](https://gitee.com/Slexy/picture/raw/master/20251110004408497.png)
传统的只将风格信息注入到残差分支中，就是红色箭头的部分，但是 ad 的优势是他不注入任何东西，他计算了一个损失值 $\mathcal{L}_{AD}$ 这个损失可以通过反向传播来更新整个模型，他的梯度可以同时流过残差分支和恒等链接的分支，他不是简单的添加风格，而是让生成的图片本体发生改变，使其的 $Q, K, V$ 特征分布逐渐学习并演变成与风格源的 $K_s, V_s$ 相匹配。

下面的 fig 4 是论文中一个非常重要的一个实验：
![image.png](https://gitee.com/Slexy/picture/raw/master/20251110155340061.png)

他证明了 ad 损失在没有任何的内容指导的情况下，仅靠自身优化的强大能力，
他展示了两大特性：
1. 风格对齐，从上面的儿童手绘图中可以看出，他可以非常精确的蒸馏出并复现参考图像的纹理和风格
2. 空间自适应：他的损失函数不是在简单的复制原图，而是真正的学会了风格（因为在这个实验的过程中他是从多个不同的随机噪声开始，以参考图为目标）这里没有使用任何的内容损失和文本提示，这是一种无条件的风格生成





**3.3 Content-preserving Optimization**
![image.png](https://gitee.com/Slexy/picture/raw/master/20251110161029457.png)

这个就是所谓的内容损失函数 $\mathcal{L}_{content}$
$$
\mathcal{L}_{content} = ∥Q −Qc∥1.
$$

他定义了内容损失为我们正在生成的图像的 Q 向量和内容参考图（结构参考图）的 Qc 向量之间的 L 1 距离，这个损失函数迫使我们生成图像的结构查询和内容参考图的结构查询保持完全一致

最后他定义了一个总损失：
$$
\mathcal{L}_{total} = \mathcal{L}_{AD} + \lambda\mathcal{L}_{content}
$$

其中有一个超参数 $\lambda$，调高 $\lambda$ 内容更重要，同样的结构也更清晰，反过来风格会更重要，图像更抽象（这段需要去看一下 $\lambda$ 是如何设置的（是随机的嘛？还是多次测试出来的））

![image.png](https://gitee.com/Slexy/picture/raw/master/20251110163911913.png)

上面就是这个实验的关于 $\lambda$ 设置的一个对比实验，可以比较直观的看出 $\lambda$ 的大小对于内容和风格之间的影响




3.3**Attention Distillation Guided Sampling**


![image.png](https://gitee.com/Slexy/picture/raw/master/20251110172300764.png)
主要介绍的是如何将这个 ad 损失集成到标注你的扩散采样过程中，来实现 ad 引导采样，
这张图对应的是公式 6 7 8 9：
他整个的过程就是 unet 先看着当前的 zt 然后听从文本提示，通过 ddim 算法，得到了 zt-1，但是在这个过程中根据公式 6 7 8 没有办法在当前将所谓的风格推力 $\nabla \mathcal{L}_{AD}$ 添加进去，因为这个方法很难配置在实验中（图 12）：

![image.png](https://gitee.com/Slexy/picture/raw/master/20251110174531043.png)

从这个实验中我们可以看到图像完全失去了风格，甚至崩溃了，所以公式 8 的这条路是走不通的

由于这个不行，所以作者提出了一个新的想法就是在生成 zt-1 之后，再把它和风格参考图一起喂给 adloss 模块，然后再去执行 zt-1，相当于在每一步的 zt-1 标准步骤之后再给他一个事后优化，然后这个过程使用的是 Adam 优化器来进行的（这个过程执行一到两步的步骤，）最后生成出图像


**3.5. Improved VAE Decoding**

这个是一个修复补丁，他是针对于 ldm（潜在扩散模型）依赖的基础工具的一个重要改进

问题的根源是 VAE （变分自编码器）是有损的，他是通过编码器和解码器来完成的，简单来说就是获取大图像压缩成效的 z，然后完成采样后将小的 z 解压回大图像 x 中，但是这个过程中存在一个问题就是，在高频局部细节中，他会损失大量的信息，这对于纹理生成和合成的问题中会带来很大的影响

这篇论文构造了一个微调解码器：

$$
\theta^{*}=arg~min_{\theta}||\mathcal{D}_{\theta}(\mathcal{E}(x))-x||_{1}
$$

就是先进行一次解压再还原后和原始图的 L 1 距离（模糊程度）用来调整编码器的参数 $\theta$ 让这个差异最小化。


![image.png](https://gitee.com/Slexy/picture/raw/master/20251110191848010.png)

这张图展现了改进的 VAE 之后和原本的对比可以显著的开出图像变得比较清晰，确保了最终生成的图像具有所需的高频细节。


4.**实验部分**

fig 6 风格与外观迁移的实验对比
（使用的方法，3.3 的内容保留优化）
![image.png](https://gitee.com/Slexy/picture/raw/master/20251110193239671.png)


fig 7 风格化 t2l 生成 （根据文本提示和一张风格图来生辰该图像）
（使用的方法，3.4 节的“AD 引导采样”）
![image.png](https://gitee.com/Slexy/picture/raw/master/20251110193251619.png)

fig 9 fig 10 纹理合成与扩展等等 ......




消融实验的研究：
fig 11 在前面有介绍过
主要是介绍这个公式 $\mathcal{L}_{total} = \mathcal{L}_{AD} + \lambda\mathcal{L}_{content}$ 中他的 $\lambda$ 起到了什么作用，本质上就是控制风格和内容之间的平衡，（证明了方法是可控的?? 又或者是证明这个方法实际上还是需要手动调...... ）

fig 12 优化器 adam 的重要性，对比了直接施加 ad 梯度和 3.4中提到的方法，就是再次计算然后使用 adam 优化器，我们发现了一个是完全失败，另外一个是完美的复现风格，说明这个方法是正确的


最后是用户偏好研究，就是调研然后发现有显著的优势胜出
![image.png](https://gitee.com/Slexy/picture/raw/master/20251110193942101.png)



关于附录：、

伪代码 1：内容保留优化 (Algorithm 1)
![image.png](https://gitee.com/Slexy/picture/raw/master/20251110200109030.png)

`Initialize z <- z^c` 1。不从随机噪声开始，而是从**内容图的潜在编码 $z^c$** 开始。这保证了优化的起点就是正确的结构。

剩下的就是按照文章来解释


伪代码 2：
![image.png](https://gitee.com/Slexy/picture/raw/master/20251110200138802.png)

`Initialize z_T ~ N(0,1)` 1。我们从**纯随机噪声 $z_T$** 开始，而不是从内容图开始。

在 7 - 9 行是一种叫做 AdaIN 的风格迁移技术将 z-1 的全局同居数据（平均色彩和对比度）和风格图的统计数据相匹配

剩下的就是 3.4 章的内容了



本地跑图：
待