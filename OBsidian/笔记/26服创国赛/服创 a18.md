
# 2026 .2.13
目前正在跑 yolov8 的基线模型：
进度如下：
![image.png](https://gitee.com/Slexy/picture/raw/master/20260213022629759.png)
时长有点久了
然后我调研了一下最近的文献（或者说和 ai 去对话了一下）
目前总结出来的模型大概是如下，可能还需要修改，但是我想先试着先去做一下，目前基本上都是 sota 的模型或者方案，部分不好做的东西可以再去调整一下：

1. **数据增强和处理方案**：
   目前想使用的方案是较为简单的随机copy-paste 或者密度copy-paste 的方案，进行一些数据增强和处理完善，处理小目标的问题
2. **主干模型**：
   经过和 ai 的沟通确实 yolov 10 可能确实会比 yolov 8 在目标识别上面会做的更好特别是对于小目标识别上面，我看了一下文献综述的话，yolov 10 被人诟病的地方主要是集中于他对于小目标可能会直接把他忽略掉（变成背景去了）不过我觉得可能影响不大，还是得先去做实际的实验我觉得会更好一些，不过暂且先使用咯
3. 颈部模型：
   这个分为两层，第一层的话，如果目前还有精力的话，可以去尝试一下 BIFPN（结构蛮复杂的）如果不太行的话，可以先用 yolov 10 原生的 PANet
   第二层的话我觉得可以使用SPD-Conv，用于解决小目标下采样的采样信息丢失问题
4. 融合中心骨干模型：
   我去看了一下曼巴模型（目前的 sota），觉得这个思路其实还是不错的，但是这个部分也算是整个里面最难的，因为环境配置非常难，不管是在 win 还是在 linux 上面，但是关于实现的话，可以去参考 ai 的这段话，我觉得这个加进去还是对于整体的项目实现有非常非常好的帮助的
   ![image.png](https://gitee.com/Slexy/picture/raw/master/20260213023938943.png)
   **但是这个对于配置环境来说，非常非常地狱，可能我需要你的帮助帮我进行配置，因为这个需要非常恶心的 cuda 版本，pytorch 版本和编译器版本，我们可以找个时间出来，我帮你配置服务集群的账号**
   如果这个没法实现的话，我们可以去降级为简单一点的 cbam 或者 sc 来进行这个多模态融合，这个我们可以考虑一下
   
5. 检测头的话我觉得就对于我们这个数据集的话我觉得砍掉 p5 检测头，然后加上一个 p2 检测头会不会更好，然后还有一个提到的，我们能不能去优化一下检测头之间的权重呢？
   （这个部分是不是可以去做一个消融实验呢？但是我们有这么多时间去做这么多事情嘛？这个地方我打个问号）


![image.png](https://gitee.com/Slexy/picture/raw/master/20260213024834464.png)






## 2026.2.13

现在进行到了第二步，我目前想就着这个先做下去，然后目前的话，我应该大概可能或许已经部署好了 mamba 模型，现在正在进行代码和数据集的调整阶段）

然后下面是后期需要注意的几个点：
训练混合模型的时候，需要考虑数据集的同位置但是不同标注的问题，即有可能只有一个数据集有标, 这个时候需要取并集，就是只要白天黑夜，只要有一个传感器能看到，那么就说明他是车（这个可能后续模型调整的时候，需要去和 ai 进行强调）

第二个事情是这个环境是：（这个是启动环境的模版）
~~~bash
# 1. 初始化 Conda (必须用绝对路径)
source /mnt/csip-099/caimingrun/miniconda3/bin/activate

# 2. 激活你的环境
conda activate /mnt/csip-099/caimingrun/envs/yolo_mamba

# 3. 可以在这里加一句 verify 确保环境加载对了 (可选)
python -c "import mamba_ssm; print('环境加载成功')"

# 4. 进入你的代码目录 (根据你实际代码位置修改)
# cd /mnt/csip-099/caimingrun/你的代码文件夹

# 5. 运行训练
# python train.py ...
~~~

